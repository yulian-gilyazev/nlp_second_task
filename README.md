#### Solution of second homework on the MIPT nlp course

## Usage example
* Training ```python3 src/train.py --train-data data/train.csv --config configs/config.json --model-path <checkpoints-path>```
* Inference ```python3 src/inference.py --train-data data/train.csv --test-data data/test.csv --prediction-path <submission-path> --config configs/config.json --model-path <model-paths>```

## Описание решения
* Была дообучена distilroberta-base на описаниях фильмов. Инференс ее в лоб дал примерно 66% accuracy на публичном тесте.
* Оказалось, что трейн и тест имеют примерно 25% пересечения. Сначала была проверена идея, что нужно предсказывать 
на этих пересечениях метки из трейна, но это сильно понижало качество на паблик лидерборде.
* Оказалось, что и внутри тестовых данных, и внутри тренировочных данных по отдельности есть дубли, поэтому размное
предположение было в том, что предполагается, что фильмы могут иметь несколько жанров.
* В итоге, на инференсе модель предсказывает фильму самый вероятный лейбл, кроме тех, которые были для для этого фильма в
тренировочных данных. Это дало заветные >75% accuracy на публичном тесте.

## Что еще можно сделать
* Датасет довольно небольшой, поэтому было бы хорошо предварительно дотюнить модель на текстах похожего домена, например, 
на датасете IMBD. Весьма вероятно, это или другие техники доменной адаптации с легкостью дали бы еще 2-3% к точности.
* Замена предсказаний на дублях из тренировочных данных дает очень большой прирост метрики. В данном решении совподающими
фильмами считались те, у которых полностью совпадали и название и описание. Вероятно, это не оптимальная стратегия, и тогда 
появляется очень большой простор для исследования данных в этом направлении.
* Проблема дублей внутри тестовых данных никак не решена. Было бы неплохо исследовать, что с этим можно сделать
* Использовать утечку в тестовых данных и получить 100% accuracy.